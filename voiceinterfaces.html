<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <style>
        @import url('https://fonts.googleapis.com/css?family=Lekton|Lato|Zilla+Slab');
        @import url("https://use.typekit.net/yzh8jbs.css");
        /* @import url('https://fonts.googleapis.com/css?family=Zilla+Slab'); */
    </style>
    <link href="grid.css" rel="stylesheet">
    <title>machine voices</title>
</head>

<body>
    <!-- Navigation -->
    <nav class="navbar fixed-top navbar-light bg-light">
        <a id="cswan" class="navbar-brand" href="index.html">Chris Swan</a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample01" aria-controls="navbarsExample01" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarsExample01">
            <ul class="navbar-nav mr-auto">
                <li class="nav-item">
                    <a class="nav-link" href="./assets/pdf/SwanUXR_Nov2019.pdf">resume</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="./contact.html"><em>information</em> </a>
                </li>
            </ul>
        </div>
    </nav>

    <!-- voice interfaces -->

    <!-- Start Container -->
    <div class="container" style="padding-top: 25px; ">

        <!-- Hero Image -->
        <div class="center">
            <img class="mv" src="./assets/img/pixelatedMan.JPG" style="padding-top: 100px; padding-bottom: 50px">

            <!-- Role Description -->
            <div>
                <div>
                    <h2 class="projects">artificial artifacts</h2>
                    <h2 class="role">Research | Web Scraping | Data Analysis | Code</h2>
                </div>
            </div>

            <!-- Project Description -->
            <div>
                <div>
                    <p>There is arguably nothing more human than our capacity towards language. Decades of applied research has developed machines that are now capable of responding to human speech. They prefer English.
                        <br>
                        <br> I explored classic research methods like in home interviews and secondary research to understand the practices, barriers, and attitudes of voice interface users. In an effort to increase the validity of my findings from the
                        interviews, I built a simple web scraper with Python to gather more data from Reddit and did a cluster analysis of feature requests.
                    </p>
                </div>
            </div>

            <!-- 0. Overview -->
            <hr>
            <div style="padding-bottom: 25px;">
                <div>
                    <div>
                        <p class="section_numbers">00</p>
                    </div>
                    <div>
                        <p class="sections">Overview</p>
                    </div>
                    <div>
                        <p class="role">A Short History of Voice Synthesis</p>
                    </div>
                </div>
                <div id="history-detail">
                    <p>Getting a machine to <em>speak</em> is not new. Debuting at the 1939 World's Fair Bell Labs first demonstrated an electronic speech synthesis device, the "Voder," developed by H.W. Dudley. This early analog system was the forerunner
                        of Bell Labs work in articulatory synthesis, conducted by Cecil Coker in the 1960s, and Joe Olive's work on concatenative synthesis in the 1970s.<sup>1</sup>
                    </p>
                    <!-- 1: https://web.archive.org/web/20140401034716/http://www.bell-labs.com/news/1997/march/5/2.html -->

                    <div>
                        <iframe src="https://www.youtube.com/embed/0rAyrmm7vv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </div>
                    <br>
                    <div>
                        <p>In 1961 IBM successfully got a computer to sing:</p>
                        <iframe src="https://www.youtube.com/embed/41U78QP8nBk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </div>
                    <br>
                    <div>
                        <p>IBM also created a voice command driven calculator <em>Shoebox:</em></p>
                        <a href="https://www.ibm.com/ibm/history/exhibits/specialprod1/specialprod1_7.html">
                            <img src="./assets/img/shoebox.jpg" alt="">
                        </a>
                    </div>
                </div>
            </div>

            <!-- 1. Research phase 1  -->
            <hr>
            <div>
                <div>
                    <div>
                        <p class="section_numbers">01</p>
                    </div>
                    <div>
                        <p class="sections">Research</p>
                    </div>
                    <div>
                        <p class="role">Secondary Research</p>
                    </div>
                </div>

                <div>
                    <p>
                        Lucy Suchman famously declared that, “objects are not innocent but fraught with significance for the relations that they materialize.<sup>1</sup>” The voice interface is the ultimate user interface. Ideally they would allow us
                        to communicate seamlessly and naturally with machines. They are the embodiment of our desire to construct a mirror of ourselves.
                        <br>
                        <br> In Voice Interfaces in Everyday Life, Martin Porcheron and Joel Fischer, explored voice interactions in detail, revealing “how the use of the Echo is made ‘at home’, as situated [through] actions, and becomes embedded in the
                        life of the home rather than that of a discrete singular isolatable event.
                        <sup>2</sup>” Through the use of sound as the interactive medium opposed to virtual connections like a mouse and keyboard, the interface is extended to a much broader environment.
                        <br>
                        <br> Wendy Hsu from the City of Los Angeles Department of Cultural Affairs notes, “software not only mediates, but also reconfigures embodiments and interactions in a digital environment. This reconfiguration goes beyond just how
                        the interface — in the case of a web site, the graphically organized wireframes and links — shapes our interactions.<sup>3</sup>"
                    </p>

                </div>
            </div>

            <!-- 2. Stats on Voice Interface uses -->
            <hr>
            <div>
                <div>
                    <div>
                        <p class="section_numbers">02</p>
                    </div>
                    <div>
                        <p class="sections">Research</p>
                    </div>
                    <div>
                        <p class="role">At Home Interviews with Katie + Harold</p>
                    </div>
                </div>

                <div>
                    <a href="">
                        <img class="thumb" src="./assets/img/katie.jpg" alt="">
                    </a>
                    <div>
                        <p>
                            <br>
                            <strong>Katie</strong>
                            <br> Age: 23 <br> User type: Light <br> Device type: Amazon Echo Dot
                        </p>
                    </div>
                    <a href="./assets/img/katie_affect.jpg">
                        <img class="affect-map" src="./assets/img/katie_affect.jpg" alt="">
                    </a>
                    <!-- <a href="">
                        <img src="./assets/img/katie_echo.jpg" alt="">
                    </a> -->
                </div>
                <div style="padding-top: 80px; padding-bottom: 50px;">
                    <a href="">
                        <img class="thumb" src="./assets/img/harold.jpg" alt="">
                    </a>
                    <div>
                        <p>
                            <br>
                            <strong>Harold</strong>
                            <br> Age: 26 <br> User type: Moderate <br> Device type: Google Home
                        </p>
                    </div>
                    <a href="./assets/img/harold_affect.jpg">
                        <img style="padding-top: 25px" class="affect-map" src="./assets/img/harold_affect.jpg" alt="">
                    </a>
                </div>
            </div>

            <!-- 3. Scraping -->
            <hr>
            <div>
                <div>
                    <div>
                        <p class="section_numbers">03</p>
                    </div>

                    <p class="sections">Improving Validity</p>
                </div>
                <div>
                    <p class="role">Web Scraping with Python and Reddit</p>
                </div>
                <div>
                    <p>
                        I wanted to explore ways to gather data from message boards that is publicly available data. I used the praw library built for Python that talks to Reddits API to make a basic web scraper for the subreddit r/AmazonEcho. The scraper pulls down the comments
                        and pushes them over to a .csv file. I used this to further analyze through clustering the requests into categories and sorting them.
                    </p>
                </div>
                <a href="https://github.com/moonstorm86/int-confidence">
                    <img style="padding-top: 25px" class="affect-map" src="./assets/img/scraper_process.jpg" alt="">
                    <p style="padding-top: 50px;"> <strong>View Code on Github</strong>
                    </p>
                </a>
            </div>


            <!-- 4. Excel and Sentiment Cluster Analysis -->
            <hr>
            <div>
                <div>
                    <p class="section_numbers">04</p>
                </div>
                <div>
                    <p class="sections">Data Analysis</p>
                </div>
                <div>
                    <p class="role">Excel and Cluster Analysis</p>
                </div>
                <div>
                    <p>
                        In Excel, I cleaned up the data and sorted it into categories. I then broke those down into subcategories and clustered those. I wanted to see if a larger picture of the user experience would emerge.
                    </p>
                </div>
                <div style="padding-bottom: 50px;">
                    <a href="">
                        <img style="padding-top: 25px" class="affect-map" src="./assets/img/analysis.JPG" alt="">
                    </a>
                </div>
            </div>

            <!-- 5. Insights -->
            <hr>
            <div>
                <div>
                    <p class="section_numbers">05</p>
                </div>

                <div>
                    <p class="sections">Insights</p>
                </div>
                <div>
                    <p class="role">What's next for Voice Interfaces?</p>
                </div>
                <div>
                    <p>The top categories of feature requests are:
                        <br>
                        <strong>Network Device <br>
                            Custom Trigger <br>
                            Chain Commands<br>
                            Volume control
                        </strong>
                    </p>
                </div>
            </div>

            <!-- 6. Reflections -->
            <!-- <hr>
            <div>
                <div>
                    <p class="section_numbers">06</p>
                </div>
                <div>
                    <p class="sections">Reflections</p>
                </div>

                <div>
                    <p class="role">Thoughts and Reflections on the Research Process</p>
                </div>
            </div>
            <br>
            <br> -->
            <hr>

        </div>
    </div>

    <br>
    <br>

    <!-- footer -->
    <div style="border-bottom: 2px black solid; padding-bottom: 10px; margin: 50px;"></div>

    <div class="container4" style="text-align: center;">
        <div class="row">
            <p class="about">web design and development by <a href="./contact.html"> me</a></p>
        </div>
    </div>

    <!-- Optional JavaScript -->
    <script src="./script.js"></script>
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous">
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous">
    </script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous">
    </script>
</body>

</html>